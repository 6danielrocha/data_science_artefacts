{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 12 - Processamento de Linguagem Natural</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao Processamento de Linguagem Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudo o que expressamos (verbalmente ou por escrito) carrega enormes quantidades de informação. \n",
    "\n",
    "O tópico que escolhemos, nosso tom, nossa seleção de palavras, tudo acrescenta algum tipo de informação que pode ser interpretada e com o valor extraído dela. Em teoria, podemos entender e até prever o comportamento humano usando essas informações.\n",
    "\n",
    "Mas há um problema: uma pessoa pode gerar centenas ou milhares de palavras em uma declaração, cada sentença com sua complexidade correspondente. Se você deseja dimensionar e analisar várias centenas, milhares ou milhões de pessoas ou declarações em uma determinada região, a situação é incontrolável.\n",
    "\n",
    "Dados gerados a partir de conversas, declarações ou até tweets são exemplos de dados não estruturados. Os dados não estruturados não se encaixam perfeitamente na estrutura tradicional de linhas e colunas de bancos de dados relacionais e representam a grande maioria dos dados disponíveis no mundo real. É confuso e difícil de manipular. \n",
    "\n",
    "No entanto, graças aos avanços em disciplinas como aprendizado de máquina, uma grande revolução está acontecendo em relação a esse tópico. Atualmente, não se trata mais de tentar interpretar um texto ou discurso com base em suas palavras-chave (a maneira mecânica antiquada), mas de entender o significado por trás dessas palavras (a maneira cognitiva). Dessa forma, é possível detectar figuras de linguagem como ironia, ou mesmo realizar análises de sentimentos.\n",
    "\n",
    "### O Que é Processamento de Linguagem Natural?\n",
    "\n",
    "O Processamento de Linguagem Natural, geralmente abreviado como PLN, é um ramo da Inteligência Artificial que lida com a interação entre computadores e seres humanos usando a linguagem natural.\n",
    "\n",
    "O objetivo final em PLN é ler, decifrar, entender e prever as linguagens humanas de uma maneira valiosa. A maioria das técnicas de PLN depende do aprendizado de máquina para derivar significado das linguagens humanas.\n",
    "\n",
    "### Casos de Uso\n",
    "\n",
    "Em termos simples, PLN representa o tratamento automático da linguagem humana natural, como fala ou texto, e, embora o conceito em si seja fascinante, o valor real por trás dessa tecnologia vem dos casos de uso.\n",
    "\n",
    "PLN pode ajudá-lo com muitas tarefas e os campos de aplicação parecem aumentar diariamente. Vamos mencionar alguns exemplos:\n",
    "\n",
    "- PLN permite o reconhecimento e a previsão de doenças com base em registros eletrônicos de saúde e na fala do próprio paciente. Essa capacidade está sendo explorada em condições de saúde que vão de doenças cardiovasculares a depressão e até esquizofrenia. Por exemplo, o Amazon Comprehend Medical é um serviço que usa PLN para extrair condições de doenças, medicamentos e resultados de tratamento de anotações de pacientes, relatórios de ensaios clínicos e outros registros eletrônicos de saúde.\n",
    "\n",
    "\n",
    "- As organizações podem determinar o que os clientes estão dizendo sobre um serviço ou produto, identificando e extraindo informações em fontes como mídia social. Essa análise de sentimentos pode fornecer muitas informações sobre as escolhas dos clientes e seus motivadores de decisão.\n",
    "\n",
    "\n",
    "- Um inventor da IBM desenvolveu um assistente cognitivo que funciona como um mecanismo de pesquisa personalizado, aprendendo tudo sobre você e depois lembrando um nome, uma música ou qualquer coisa que você não consegue lembrar no momento em que precisa.\n",
    "\n",
    "\n",
    "- Empresas como Yahoo e Google filtram e classificam seus e-mails com PLN, analisando o texto nos e-mails que fluem através de seus servidores e interrompendo o spam antes mesmo de entrarem na sua caixa de entrada.\n",
    "\n",
    "\n",
    "- Para ajudar a identificar notícias falsas, o Grupo NLP do MIT desenvolveu um novo sistema para determinar se uma fonte é precisa ou politicamente tendenciosa, detectando se uma fonte de notícias pode ser confiável ou não.\n",
    "\n",
    "\n",
    "- O Alexa da Amazon e o Siri da Apple são exemplos de interfaces inteligentes orientadas por voz que usam PLN para responder às solicitações vocais e fazem de tudo, como encontrar uma loja em particular, informar a previsão do tempo, sugerir o melhor caminho para o escritório ou acender as luzes em casa.\n",
    "\n",
    "\n",
    "- Ter uma ideia do que está acontecendo e do que as pessoas estão falando pode ser muito valioso para os operadores financeiros. PLN está sendo usada para rastrear notícias, relatórios, comentários sobre possíveis fusões entre empresas; tudo pode ser incorporado a um algoritmo de negociação para gerar lucros maciços. Lembre-se: compre o boato, venda as notícias.\n",
    "\n",
    "\n",
    "- PLN também está sendo usado nas fases de busca e seleção do recrutamento de talentos, identificando as habilidades de possíveis contratados e também identificando perspectivas antes que elas se tornem ativas no mercado de trabalho.\n",
    "\n",
    "- Desenvolvido pela tecnologia IBM Watson NLP, o LegalMation desenvolveu uma plataforma para automatizar tarefas rotineiras de litígio e ajudar as equipes jurídicas a economizar tempo, reduzir custos e mudar o foco estratégico.\n",
    "\n",
    "E os exemplos não param. PLN é um campo ativo e cada vez mais presente em nossas vidas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação do pacote NLTK\n",
    "http://www.nltk.org/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.nltk.org/book/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação do módulo NLTK\n",
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacao do modulo spacy - https://spacy.io/usage\n",
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "spacy : 2.3.4\n",
      "re    : 2.2.1\n",
      "numpy : 1.17.2\n",
      "nltk  : 3.4.5\n",
      "pandas: 0.25.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando os arquivos de dados e dicionários do NLTK\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de dividir uma string em listas de pedaços ou \"tokens\". Um token é uma parte inteira. Por exemplos: uma palavra é um token em uma sentença. Uma sentença é um token em um parágrafo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo um Parágrafo em Frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragrafo = \"Seja Bem-vindo a Data Science Academy. Bom saber que você está aprendendo PLN. Obrigado por estar conosco.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a sentence-tokenized copy of *text*,\n",
       "using NLTK's recommended sentence tokenizer\n",
       "(currently :class:`.PunktSentenceTokenizer`\n",
       "for the specified language).\n",
       "\n",
       ":param text: text to split into sentences\n",
       ":param language: the model name in the Punkt corpus\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o parágrafo em frases\n",
    "frases = sent_tokenize(paragrafo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seja Bem-vindo a Data Science Academy.', 'Bom saber que você está aprendendo PLN.', 'Obrigado por estar conosco.']\n"
     ]
    }
   ],
   "source": [
    "print(frases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando um dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando dicionário do pacote NLTK\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/portuguese.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seja Bem-vindo a Data Science Academy.',\n",
       " 'Bom saber que você está aprendendo PLN.',\n",
       " 'Obrigado por estar conosco.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(paragrafo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário em espanhol\n",
    "spanish_tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola amigo.', 'Estoy bien.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_tokenizer.tokenize('Hola amigo. Estoy bien.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo uma Frase em Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data', 'Science', 'Academy']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('Data Science Academy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inteligência', 'Artificial']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Inteligência Artificial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', \"n't\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"can't\") # cannot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can', \"'\", 't', 'is', 'a', 'contraction', '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Can't is a contraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(\"[\\w']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Can't\", 'is', 'a', 'contraction']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Can't is a contraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mregexp_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdiscard_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mRegexFlag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mMULTILINE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m56\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a tokenized copy of *text*.  See :class:`.RegexpTokenizer`\n",
       "for descriptions of the arguments.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/regexp.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Can't\", 'is', 'a', 'contraction']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(\"Can't is a contraction.\", \"[\\w']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\s+', gaps = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Can't\", 'is', 'a', 'contraction.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Can't is a contraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Seja', 'Bem-vindo', 'a', 'Data', 'Science', 'Academy', '.'], ['Bom', 'saber', 'que', 'você', 'está', 'aprendendo', 'PLN', '.'], ['Obrigado', 'por', 'estar', 'conosco', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Uma operação única com List Comprehension\n",
    "\n",
    "# Texto a ser tokenizado\n",
    "texto = \"Seja Bem-vindo a Data Science Academy. Bom saber que você está aprendendo PLN. Obrigado por estar conosco.\"\n",
    "\n",
    "# List Comprehension\n",
    "print([word_tokenize(frase) for frase in sent_tokenize(texto)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords são palavras comuns que normalmente não contribuem para o significado de uma frase, pelo menos com relação ao propósito da informação e do processamento da linguagem natural. São palavras como \"The\" e \"a\" ((em inglês) ou \"O/A\" e \"Um/Uma\" ((em português). Muitos mecanismos de busca filtram estas palavras (stopwords), como forma de economizar espaço em seus índices de pesquisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = [\"Can't\", 'is', 'a', 'contraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Can't\", 'contraction']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[palavra for palavra in palavras if palavra not in english_stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "portuguese_stops = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = [\"Aquilo\", 'é', 'uma', 'ferrari']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aquilo', 'ferrari']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[palavra for palavra in palavras if palavra not in portuguese_stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet é um banco de dados léxico (em Inglês). É uma espécie de dicionário criado especificamente para processamento de linguagem natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m           WordNetCorpusReader\n",
       "\u001b[0;31mString form:\u001b[0m    <WordNetCorpusReader in '/home/daniel/nltk_data/corpora/wordnet'>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\n",
       "\u001b[0;31mDocstring:\u001b[0m      A corpus reader used to access wordnet or its variants.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a new wordnet corpus reader, with the given root\n",
       "directory.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Load all synsets with a given lemma and part of speech tag.\n",
       "If no pos is specified, all synsets for all parts of speech\n",
       "will be loaded.\n",
       "If lang is specified, all the synsets associated with the lemma name\n",
       "of that language will be returned.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/wordnet.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?wordnet.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = wordnet.synsets('cookbook')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.wordnet.Synset"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cookbook.n.01'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book of recipes and cooking directions'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking can be a great art',\n",
       " 'people are needed who have experience in cookery',\n",
       " 'he left the preparation of meals to his wife']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('cooking')[0].examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming e Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por razões gramaticais, os documentos usarão diferentes formas de uma palavra, como por exemplo: \n",
    "\n",
    "organizar, organizado e organizando. \n",
    "\n",
    "Além disso, existem famílias de palavras derivadamente relacionadas com significados semelhantes, como democracia, democrático e democratização. Em muitas situações, pode ser útil procurar uma dessas palavras para retornar documentos que contenham outra palavra no conjunto.\n",
    "\n",
    "O objetivo da Derivação (Stemming) e da Lematização (Lemmatization) é reduzir as formas flexionadas e, às vezes, derivadas de uma palavra para uma base comum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "Stemming é a técnica de remover sufixos e prefixos de uma palavra, chamada stem. Por exemplo, o stem da palavra cooking é cook. Um bom algoritmo sabe que \"ing\" é um sufixo e pode ser removido. Stemming é muito usado em mecanismos de buscas para indexação de palavras. Ao invés de armazenar todas as formas de uma palavra, um mecamismo de busca armazena apenas o stem da palavra, reduzindo o tamanho do índice e aumentando a performance do processo de busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cook'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer.stem('cooking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cookeri'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer.stem('cookery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanc_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cook'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lanc_stemmer.stem('cooking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cookery'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lanc_stemmer.stem('cookery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_stemmer = RegexpStemmer('ing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cook'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_stemmer.stem('cooking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_palavras = [\"cat\", \"cats\", \"know\", \"knowing\", \"time\", \"timing\", \"football\", \"footballers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat -> cat\n",
      "cats -> cat\n",
      "know -> know\n",
      "knowing -> know\n",
      "time -> time\n",
      "timing -> time\n",
      "football -> footbal\n",
      "footballers -> footbal\n"
     ]
    }
   ],
   "source": [
    "for palavra in lista_palavras:\n",
    "    print(palavra + ' -> ' + porter_stemmer.stem(palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentenceStemmer(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    stems = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentenceStemmer('The cats and dogs are running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization leva em consideração a análise morfológica das palavras. Para fazer isso, é necessário ter dicionários detalhados nos quais o algoritmo possa procurar para vincular o formulário ao seu lema. Veja um exemplo:\n",
    "\n",
    "- Forma flexionada: organizando\n",
    "- Lema: organiza\n",
    "\n",
    "- Forma flexionada: organizado\n",
    "- Lema: organiza\n",
    "\n",
    "Com Lemmatization as duas formas flexionadas organizando e organizado seria representadas somente pelo lema organiza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse\n",
      "cactus\n",
      "horse\n",
      "wolf\n"
     ]
    }
   ],
   "source": [
    "print(wordnet_lemmatizer.lemmatize('mice'))\n",
    "print(wordnet_lemmatizer.lemmatize('cacti'))  # plural da palavra cactus - cactuses (inglês) ou cacti (latin)\n",
    "print(wordnet_lemmatizer.lemmatize('horses'))\n",
    "print(wordnet_lemmatizer.lemmatize('wolves'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "madeupwords\n",
      "madeupword\n"
     ]
    }
   ],
   "source": [
    "print(wordnet_lemmatizer.lemmatize('madeupwords'))\n",
    "print(porter_stemmer.stem('madeupwords'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-Speech Tag (PoS-Tag)\n",
    "\n",
    "http://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_word_pos_tuples(sentence):\n",
    "    return pos_tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The cats and dogs are running'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_word_pos_tuples(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_wordnet(pos_tag):\n",
    "    pos_dict = {\"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"J\": wordnet.ADJ,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return pos_dict.get(pos_tag[0].upper(), wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pos_wordnet('VBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_pos(sentence):\n",
    "    new_sentence = []\n",
    "    tuples = return_word_pos_tuples(sentence)\n",
    "    for tup in tuples:\n",
    "        pos = get_pos_wordnet(tup[1])\n",
    "        lemma = wordnet_lemmatizer.lemmatize(tup[0], pos = pos)\n",
    "        new_sentence.append(lemma)\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lemmatize_with_pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus é uma coleção de documentos de texto e Corpora é o plural de Corpus. Esse termo vem da palavra em Latim para corpo (nesse caso, o corpo de um texto). Um Corpus customizado é uma coleção de arquivos de texto organizados em um diretório.\n",
    "\n",
    "Se você for treinar seu próprio modelo como parte de um processo de classificação de texto (como análise de texto), você terá que criar seu próprio Corpus e treiná-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdir = 'corpus/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorpus = PlaintextCorpusReader(corpusdir, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints/palavras1-checkpoint.txt',\n",
       " 'palavras1.txt',\n",
       " 'palavras2.txt',\n",
       " 'palavras3.txt']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcorpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints/palavras1-checkpoint.txt\n",
      "palavras1.txt\n",
      "palavras2.txt\n",
      "palavras3.txt\n"
     ]
    }
   ],
   "source": [
    "# Acessando cada arquivo no Corpus com loop for\n",
    "for infile in sorted(newcorpus.fileids()):\n",
    "    print(infile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints/palavras1-checkpoint.txt',\n",
       " 'palavras1.txt',\n",
       " 'palavras2.txt',\n",
       " 'palavras3.txt']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acessando cada arquivo no Corpus com list comprehension\n",
    "[arquivo for arquivo in sorted(newcorpus.fileids())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big Data\n",
      "Data Science\n",
      "Inteligência Artificial\n",
      "Deep LearningBig Data\n",
      "Data Science\n",
      "Inteligência Artificial\n",
      "Deep LearningMercado de Trabalho\n",
      "Cientista de Dados\n",
      "Engenheiro de Machine Learning\n",
      "Engenheiro de IAEmpresas\n",
      "Recursos Humanos\n",
      "Pessoas\n",
      "Contratação\n"
     ]
    }
   ],
   "source": [
    "# Conteúdo do Corpus\n",
    "print(newcorpus.raw().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Big', 'Data', 'Data', 'Science', 'Inteligência', 'Artificial', 'Deep', 'Learning']], [['Big', 'Data', 'Data', 'Science', 'Inteligência', 'Artificial', 'Deep', 'Learning']], ...]\n"
     ]
    }
   ],
   "source": [
    "# Conteúdo do Corpus tokenizado por parágrafo (nova linha)\n",
    "print(newcorpus.paras())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Big', 'Data', 'Data', 'Science', 'Inteligência', 'Artificial', 'Deep', 'Learning'], ['Big', 'Data', 'Data', 'Science', 'Inteligência', 'Artificial', 'Deep', 'Learning'], ...]\n"
     ]
    }
   ],
   "source": [
    "# Conteúdo do Corpus tokenizado por sentença (nova linha)\n",
    "print(newcorpus.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Big', 'Data', 'Data', 'Science', 'Inteligência', 'Artificial', 'Deep', 'Learning']]\n"
     ]
    }
   ],
   "source": [
    "# Conteúdo do Corpus tokenizado por sentença por arquivo\n",
    "print(newcorpus.sents(newcorpus.fileids()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O NLTK traz diversos Corpus e Corpora que podem ser usados para os mais variados fins. Vamos expermentar o Corpus do Projeto Gutenberg: https://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gt.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', ...]\n"
     ]
    }
   ],
   "source": [
    "shakespeare_macbeth = gt.words(\"shakespeare-macbeth.txt\")\n",
    "print(shakespeare_macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = gt.raw(\"shakespeare-macbeth.txt\")\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[The Tragedie of Macbeth by William Shakespeare 1603]\n",
    "\n",
    "\n",
    "Actus Primus. Scoena Prima.\n",
    "\n",
    "Thunder and Lightning. Enter three Witches.\n",
    "\n",
    "  1. When shall we three meet againe?\n",
    "In Thunder, Lightning, or in Raine?\n",
    "  2. When the Hurley-burley's done,\n",
    "When the Battaile's lost, and wonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "sents = gt.sents(\"shakespeare-macbeth.txt\")\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileid in gt.fileids():\n",
    "    num_words = len(gt.words(fileid))\n",
    "    num_sents = len(gt.sents(fileid))\n",
    "    print(\"Dados do Arquivo:\", fileid)\n",
    "    print(\"Número de Palavras:\", num_words)\n",
    "    print(\"Número de Frases:\", num_sents, end = \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab - Collocations e Processamento de Comentários de Avaliações de Hotéis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations são duas ou mais palavras que tendem a aparecer frequentemente juntas, como \"Estados Unidos\", \"Rio Grande do Sul\" ou \"Machine Learning\". Essas palavras podem gerar diversas combinações e por isso o contexto também é importante no processamento de linguagem natural.\n",
    "\n",
    "Os dois tipos mais comuns de Collocations são bigramas e trigramas. Bigramas são duas palavras adjacentes, como \"tomografia computadorizada\", \"aprendizado de máquina\" ou \"mídia social\". Trigramas são três palavras adjacentes, como \"fora do negócio\" ou \"Proctor and Gamble\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bigramas: (Nome, Nome), (Adjetivo, Nome)\n",
    "- Trigramas: (Adjetivo/Nome, Qualquer_Item, Adjetivo/Nome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas se escolhermos palavras adjacentes como bigrama ou trigramas, não obteremos frases significativas. Por exemplo, a frase 'Ele usa mídias sociais' contém bigramas: 'Ele usa', 'usa mídias', 'mídias sociais'. \"Ele usa\" e \"usa mídias\" não significa nada, enquanto \"mídias sociais\" é um bigrama significativo. \n",
    "\n",
    "Como fazemos boas seleções para Collocations? As co-ocorrências podem não ser suficientes, pois frases como 'assim como' podem co-ocorrer com frequência, mas não são significativas. Vamos explorar vários métodos para filtrar as Collocations mais significativas: contagem de frequências, informação mútua pontual (PMI) e teste de hipóteses (teste t e qui-quadrado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do Problema\n",
    "\n",
    "Dado um conjunto de texto de avaliações (comentários) de hotéis, vamos buscar as Collocations mais relevantes que ajudam a explicar as avaliações!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se necessário, instale pacotes que não estejam instalados\n",
    "!pip install -q spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se necessário, faça o download das stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando dados de avaliações de hotéis\n",
    "# Fonte de dados: https://datafiniti.co/products/business-data/\n",
    "avaliacoes_hoteis = pd.read_csv('https://raw.githubusercontent.com/dsacademybr/Datasets/master/dataset7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>address</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>keys</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>websites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AVwc252WIN2L1WUfpqLP</td>\n",
       "      <td>2016-10-30T21:42:42Z</td>\n",
       "      <td>2018-09-10T21:06:27Z</td>\n",
       "      <td>5921 Valencia Cir</td>\n",
       "      <td>Hotels,Hotels and motels,Hotel and motel reser...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rancho Santa Fe</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/ranchosantafe/5921valenciacir/359754519</td>\n",
       "      <td>32.990959</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-08-03T00:00:00Z,2016-07-26T00:00:00Z,2016...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.hotels.com/hotel/125419/reviews%20/</td>\n",
       "      <td>Our experience at Rancho Valencia was absolute...</td>\n",
       "      <td>Best romantic vacation ever!!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paula</td>\n",
       "      <td>http://www.hotels.com/ho125419/%25252525253Flo...</td>\n",
       "      <td>http://www.ranchovalencia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AVwc252WIN2L1WUfpqLP</td>\n",
       "      <td>2016-10-30T21:42:42Z</td>\n",
       "      <td>2018-09-10T21:06:27Z</td>\n",
       "      <td>5921 Valencia Cir</td>\n",
       "      <td>Hotels,Hotels and motels,Hotel and motel reser...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rancho Santa Fe</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/ranchosantafe/5921valenciacir/359754519</td>\n",
       "      <td>32.990959</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-08-02T00:00:00Z,2016-08-26T00:00:00Z,2016...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.hotels.com/hotel/125419/reviews%20/</td>\n",
       "      <td>Amazing place. Everyone was extremely warm and...</td>\n",
       "      <td>Sweet sweet serenity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>http://www.hotels.com/ho125419/%25252525253Flo...</td>\n",
       "      <td>http://www.ranchovalencia.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             dateAdded           dateUpdated  \\\n",
       "0  AVwc252WIN2L1WUfpqLP  2016-10-30T21:42:42Z  2018-09-10T21:06:27Z   \n",
       "1  AVwc252WIN2L1WUfpqLP  2016-10-30T21:42:42Z  2018-09-10T21:06:27Z   \n",
       "\n",
       "             address                                         categories  \\\n",
       "0  5921 Valencia Cir  Hotels,Hotels and motels,Hotel and motel reser...   \n",
       "1  5921 Valencia Cir  Hotels,Hotels and motels,Hotel and motel reser...   \n",
       "\n",
       "               primaryCategories             city country  \\\n",
       "0  Accommodation & Food Services  Rancho Santa Fe      US   \n",
       "1  Accommodation & Food Services  Rancho Santa Fe      US   \n",
       "\n",
       "                                            keys   latitude  ...  \\\n",
       "0  us/ca/ranchosantafe/5921valenciacir/359754519  32.990959  ...   \n",
       "1  us/ca/ranchosantafe/5921valenciacir/359754519  32.990959  ...   \n",
       "\n",
       "                                    reviews.dateSeen reviews.rating  \\\n",
       "0  2016-08-03T00:00:00Z,2016-07-26T00:00:00Z,2016...            5.0   \n",
       "1  2016-08-02T00:00:00Z,2016-08-26T00:00:00Z,2016...            5.0   \n",
       "\n",
       "                                reviews.sourceURLs  \\\n",
       "0  https://www.hotels.com/hotel/125419/reviews%20/   \n",
       "1  https://www.hotels.com/hotel/125419/reviews%20/   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  Our experience at Rancho Valencia was absolute...   \n",
       "1  Amazing place. Everyone was extremely warm and...   \n",
       "\n",
       "                     reviews.title reviews.userCity  reviews.userProvince  \\\n",
       "0  Best romantic vacation ever!!!!              NaN                   NaN   \n",
       "1             Sweet sweet serenity              NaN                   NaN   \n",
       "\n",
       "  reviews.username                                         sourceURLs  \\\n",
       "0            Paula  http://www.hotels.com/ho125419/%25252525253Flo...   \n",
       "1                D  http://www.hotels.com/ho125419/%25252525253Flo...   \n",
       "\n",
       "                        websites  \n",
       "0  http://www.ranchovalencia.com  \n",
       "1  http://www.ranchovalencia.com  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados\n",
    "avaliacoes_hoteis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo do objeto\n",
    "type(avaliacoes_hoteis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 25)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "avaliacoes_hoteis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar dataframe em /\n",
    "avaliacoes_hoteis.to_csv(\"dados/avaliacoes_hoteis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo as avaliações\n",
    "comentarios = avaliacoes_hoteis['reviews.text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(comentarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte para o tipo string\n",
    "comentarios = comentarios.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover caracteres non-ascii \n",
    "def removeNoAscii(s): \n",
    "    return \"\".join(i for i in s if ord(i) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'345abc&'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "removeNoAscii(\"¥¥¥345abc&£££\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove caracteres non-ascii \n",
    "comentarios = comentarios.map(lambda x: removeNoAscii(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Our experience at Rancho Valencia was absolute...\n",
      "1       Amazing place. Everyone was extremely warm and...\n",
      "2       We booked a 3 night stay at Rancho Valencia to...\n",
      "3       Currently in bed writing this for the past hr ...\n",
      "4       I live in Md and the Aloft is my Home away fro...\n",
      "                              ...                        \n",
      "9995    It is hard for me to review an oceanfront hote...\n",
      "9996    I live close by, and needed to stay somewhere ...\n",
      "9997    Rolled in 11:30 laid out heads down woke up to...\n",
      "9998    Absolutely terrible..I was told I was being gi...\n",
      "9999    Filthy, outdated, noisy neighbours, but this w...\n",
      "Name: reviews.text, Length: 10000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(comentarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém as stopwords em todos os idiomas\n",
    "# quebra de linha \\\n",
    "dicionario_stopwords = {lang: set(nltk.corpus.stopwords.words(lang)) \\\n",
    "                        for lang in nltk.corpus.stopwords.fileids()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordpunct_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a tokenized copy of *s*.\n",
       "\n",
       ":rtype: list of str\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/regexp.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nltk.wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digerindo a funcao que identifica idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = set(nltk.wordpunct_tokenize(\"Meu mundo é bonito!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!', 'Meu', 'bonito', 'mundo', 'é'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaT = [(lang, len(palavras & stopwords)) for lang, stopwords in dicionario_stopwords.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arabic', 0),\n",
       " ('azerbaijani', 0),\n",
       " ('danish', 0),\n",
       " ('dutch', 0),\n",
       " ('english', 0),\n",
       " ('finnish', 0),\n",
       " ('french', 0),\n",
       " ('german', 0),\n",
       " ('greek', 0),\n",
       " ('hungarian', 0),\n",
       " ('indonesian', 0),\n",
       " ('italian', 0),\n",
       " ('kazakh', 0),\n",
       " ('nepali', 0),\n",
       " ('norwegian', 0),\n",
       " ('portuguese', 1),\n",
       " ('romanian', 0),\n",
       " ('russian', 0),\n",
       " ('slovene', 0),\n",
       " ('spanish', 0),\n",
       " ('swedish', 0),\n",
       " ('tajik', 0),\n",
       " ('turkish', 0)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('portuguese', 1)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(listaT, key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'portuguese'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(listaT, key = lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para detectar o idioma predominante com base nas stopwords\n",
    "def descobre_idioma(text):\n",
    "    \n",
    "    # Aplica tokenização considerando pontuação\n",
    "    palavras = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    \n",
    "    # Conta o total de palavras tokenizadas considerando o dicionário de stopwords\n",
    "    lang = max(((lang, len(palavras & stopwords)) for lang, stopwords in dicionario_stopwords.items()), \\\n",
    "               key = lambda x: x[1])[0]\n",
    "    \n",
    "    # Verifica se o idioma é português\n",
    "    if lang == 'portuguese':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra somente os comentários em português\n",
    "comentarios_portugues = comentarios[comentarios.apply(descobre_idioma)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "comentarios_portugues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5531    Hotel confortavel, porem com algumas instalaco...\n",
       "5658    Adorei! Recomendo a todos! Apesar de nao ficar...\n",
       "5693    O hotel e meio longe do centro de Washington, ...\n",
       "5765    Perto de uma estacao de metro. Transporte grat...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print\n",
    "comentarios_portugues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para detectar o idioma predominante com base nas stopwords\n",
    "def descobre_idioma(text):\n",
    "    words = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    lang = max(((lang, len(words & stopwords)) for lang, stopwords in dicionario_stopwords.items()), key = lambda x: x[1])[0]\n",
    "    if lang == 'english':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra somente os comentários em português\n",
    "comentarios_ingles = comentarios[comentarios.apply(descobre_idioma)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9725,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "comentarios_ingles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our experience at Rancho Valencia was absolute...\n",
       "1    Amazing place. Everyone was extremely warm and...\n",
       "2    We booked a 3 night stay at Rancho Valencia to...\n",
       "3    Currently in bed writing this for the past hr ...\n",
       "4    I live in Md and the Aloft is my Home away fro...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print\n",
    "comentarios_ingles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo duplicidades\n",
    "comentarios_ingles.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9718,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "comentarios_ingles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/daniel/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: setuptools in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (41.4.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.17.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.53.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/daniel/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/daniel/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/daniel/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/daniel/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/daniel/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Baixando o dicionário inglês\n",
    "# https://spacy.io/usage/models\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pode ser necessário reiniciar o Jupyter Notebook para executar a célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dcionário em nossa sessão SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para limpar e lematizar os comentários\n",
    "def limpa_comentarios(text):\n",
    "    \n",
    "    # Remove pontuação usando expressão regular\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    \n",
    "    # Usa o SpaCy para lematização\n",
    "    doc = nlp(nopunct, disable = ['parser', 'ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função aos dados\n",
    "comentarios_ingles_lemmatized = comentarios_ingles.map(limpa_comentarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloca tudo em minúsculo\n",
    "comentarios_ingles_lemmatized = comentarios_ingles_lemmatized.map(lambda x: [word.lower() for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-pron-, experience, at, rancho, valencia, be,...\n",
       "1    [amazing, place,  , everyone, be, extremely, w...\n",
       "2    [-pron-, book, a, 3, night, stay, at, rancho, ...\n",
       "3    [currently, in, bed, write, this, for, the, pa...\n",
       "4    [-pron-, live, in, md, and, the, aloft, be, -p...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados\n",
    "comentarios_ingles_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos tokenizar os comentários\n",
    "comentarios_tokens = [item for items in comentarios_ingles_lemmatized for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-pron-',\n",
       " 'experience',\n",
       " 'at',\n",
       " 'rancho',\n",
       " 'valencia',\n",
       " 'be',\n",
       " 'absolutely',\n",
       " 'perfect']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens\n",
    "comentarios_tokens[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(comentarios_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estratégia 1 - Buscando Bigramas e Trigramas Mais Relevantes nos Comentários Por Frequência\n",
    "\n",
    "Nossa primeira estratégia é a mais simples de todas: contagem de frequência. Contamos quantas vezes cada Collocation aparece no texto e filtramos pelos Collocations mais frequentes.\n",
    "\n",
    "Vamos filtrar apenas os adjetivos e substantivos para reduzir o tempo de processamento e vamos contar a frequência dos Collocations, bigramas e trigramas, nos comentários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de associação de bigramas (esse objeto possui diversos atributos, como freq, pmi, teste t, etc...)\n",
    "bigramas = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de associação de trigramas\n",
    "trigramas = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O próximo passo é criar um buscador de bigramas nos tokens\n",
    "buscaBigramas = nltk.collocations.BigramCollocationFinder.from_words(comentarios_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazemos o mesmo com trigramas. Fique atento aos métodos que estão sendo usados\n",
    "buscaTrigramas = nltk.collocations.TrigramCollocationFinder.from_words(comentarios_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos contar quantas vezes cada bigrama aparece nos tokens dos comentários\n",
    "bigrama_freq = buscaBigramas.ngram_fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência dos bigramas\n",
    "bigrama_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bigrama_freq)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dict_items([(('-pron-', 'experience'), 155), (('experience', 'at'), 59), (('at', 'rancho'), 2), (('rancho', 'valencia'), 2), (('valencia', 'be'), 1), (('be', 'absolutely'), 52), (('absolutely', 'perfect'), 6), (('perfect', 'from'), 1), (('from', 'begin'), 8), (('begin', 'to'), 19), (('to', 'end'), 11), (('end', '    '), 1), (('    ', '-pron-'), 40), (('-pron-', 'feel'), 282), (('feel', 'special'), 9), (('special', 'and'), 8), (('and', 'very'), 346), (('very', 'happy'), 57),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos converter o dicionário anterior em uma tabela de frequência no formato do Pandas para os bigramas\n",
    "FreqTabBigramas = pd.DataFrame(list(bigrama_freq), \n",
    "                               columns = ['Bigrama', 'Freq']).sort_values(by = 'Freq', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigrama</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>( , -pron-)</td>\n",
       "      <td>11870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>( , the)</td>\n",
       "      <td>8731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>(-pron-, be)</td>\n",
       "      <td>6833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>(-pron-, have)</td>\n",
       "      <td>3241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>(the, room)</td>\n",
       "      <td>3157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bigrama   Freq\n",
       "22      ( , -pron-)  11870\n",
       "128        ( , the)   8731\n",
       "102    (-pron-, be)   6833\n",
       "279  (-pron-, have)   3241\n",
       "288     (the, room)   3157"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "FreqTabBigramas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos contar quantas vezes cada trigrama aparece nos tokens dos comentários\n",
    "trigrama_freq = buscaTrigramas.ngram_fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de frequência no formato do Pandas para os trigramas\n",
    "FreqTabTrigramas = pd.DataFrame(list(trigrama_freq), \n",
    "                                columns = ['Trigrama','Freq']).sort_values(by = 'Freq', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigrama</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>626</td>\n",
       "      <td>( , -pron-, be)</td>\n",
       "      <td>2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>(the, room, be)</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>( , the, room)</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>(the, staff, be)</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>( , -pron-, have)</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Trigrama  Freq\n",
       "626    ( , -pron-, be)  2575\n",
       "310    (the, room, be)  1640\n",
       "309     ( , the, room)  1381\n",
       "138   (the, staff, be)  1088\n",
       "298  ( , -pron-, have)  1064"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "FreqTabTrigramas.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos muitas stopwords. Vamos removê-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar uma lista de stopwords\n",
    "en_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para filtrar bigramas ADJ/NN e remover stopwords\n",
    "def filtra_tipo_token_bigrama(ngram):\n",
    "    \n",
    "    # Verifica se é pronome\n",
    "    if '-pron-' in ngram or 't' in ngram:\n",
    "        return False\n",
    "    \n",
    "    # Loop nos ngramas para verificar se é stopword\n",
    "    for word in ngram:\n",
    "        if word in en_stopwords or word.isspace():\n",
    "            return False\n",
    "        \n",
    "    # Tipos de tokens aceitáveis\n",
    "    acceptable_types = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    \n",
    "    # Subtipos\n",
    "    second_type = ('NN', 'NNS', 'NNP', 'NNPS')\n",
    "    \n",
    "    # Tags\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    \n",
    "    # Retorna o que queremos, ADJ/NN\n",
    "    if tags[0][1] in acceptable_types and tags[1][1] in second_type:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora filtramos os bigramas\n",
    "bigramas_filtrados = FreqTabBigramas[FreqTabBigramas.Bigrama.map(lambda x: filtra_tipo_token_bigrama(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigrama</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>(front, desk)</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>(friendly, staff)</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>(great, location)</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1553</td>\n",
       "      <td>(walk, distance)</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>(clean, room)</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>(free, breakfast)</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>(customer, service)</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641</td>\n",
       "      <td>(desk, staff)</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1733</td>\n",
       "      <td>(hotel, staff)</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>(continental, breakfast)</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1639</td>\n",
       "      <td>(comfortable, bed)</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25100</td>\n",
       "      <td>(good, western)</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>(nice, hotel)</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6185</td>\n",
       "      <td>(next, door)</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1148</td>\n",
       "      <td>(great, place)</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1392</td>\n",
       "      <td>(parking, lot)</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1647</td>\n",
       "      <td>(hampton, inn)</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3886</td>\n",
       "      <td>(good, location)</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>(next, time)</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12631</td>\n",
       "      <td>(pool, area)</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Bigrama  Freq\n",
       "193               (front, desk)   943\n",
       "546           (friendly, staff)   344\n",
       "372           (great, location)   334\n",
       "1553           (walk, distance)   274\n",
       "1125              (clean, room)   240\n",
       "348           (free, breakfast)   198\n",
       "686         (customer, service)   191\n",
       "641               (desk, staff)   189\n",
       "1733             (hotel, staff)   189\n",
       "1680   (continental, breakfast)   180\n",
       "1639         (comfortable, bed)   174\n",
       "25100           (good, western)   168\n",
       "630               (nice, hotel)   166\n",
       "6185               (next, door)   158\n",
       "1148             (great, place)   157\n",
       "1392             (parking, lot)   144\n",
       "1647             (hampton, inn)   139\n",
       "3886           (good, location)   137\n",
       "6000               (next, time)   135\n",
       "12631              (pool, area)   127"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "bigramas_filtrados.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para filtrar trigramas ADJ/NN e remover stopwords\n",
    "def filtra_tipo_token_trigrama(ngram):\n",
    "    \n",
    "    # Verifica se é pronome\n",
    "    if '-pron-' in ngram or 't' in ngram:\n",
    "        return False\n",
    "    \n",
    "    # Loop nos ngramas para verificar se é stopword\n",
    "    for word in ngram:\n",
    "        if word in en_stopwords or word.isspace():\n",
    "            return False\n",
    "        \n",
    "    # Tipos de tokens aceitáveis\n",
    "    first_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    \n",
    "    # Subtipos\n",
    "    second_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    \n",
    "    # Tags\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    \n",
    "    # Retorna o que queremos, ADJ/NN\n",
    "    if tags[0][1] in first_type and tags[2][1] in second_type:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora filtramos os trigramas\n",
    "trigramas_filtrados = FreqTabTrigramas[FreqTabTrigramas.Trigrama.map(lambda x: filtra_tipo_token_trigrama(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigrama</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>759</td>\n",
       "      <td>(front, desk, staff)</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8441</td>\n",
       "      <td>(non, smoking, room)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50170</td>\n",
       "      <td>(front, desk, clerk)</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26902</td>\n",
       "      <td>(regis, new, york)</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119596</td>\n",
       "      <td>(holiday, inn, express)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71764</td>\n",
       "      <td>(suites, anaheim, maingate)</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50060</td>\n",
       "      <td>(flat, screen, tv)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64829</td>\n",
       "      <td>(hilton, garden, inn)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71766</td>\n",
       "      <td>(maingate, near, angel)</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26998</td>\n",
       "      <td>(octavia, margineanhotel, manager)</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57163</td>\n",
       "      <td>(hampton, inn, suites)</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24435</td>\n",
       "      <td>(good, night, sleep)</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26653</td>\n",
       "      <td>(new, york, city)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50576</td>\n",
       "      <td>(first, time, stay)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36210</td>\n",
       "      <td>(front, desk, people)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>(excellent, customer, service)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58894</td>\n",
       "      <td>(front, desk, person)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2639</td>\n",
       "      <td>(air, conditioning, unit)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6981</td>\n",
       "      <td>(great, customer, service)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41181</td>\n",
       "      <td>(hard, boil, egg)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Trigrama  Freq\n",
       "759                   (front, desk, staff)   162\n",
       "8441                  (non, smoking, room)    40\n",
       "50170                 (front, desk, clerk)    38\n",
       "26902                   (regis, new, york)    37\n",
       "119596             (holiday, inn, express)    32\n",
       "71764          (suites, anaheim, maingate)    30\n",
       "50060                   (flat, screen, tv)    29\n",
       "64829                (hilton, garden, inn)    29\n",
       "71766              (maingate, near, angel)    27\n",
       "26998   (octavia, margineanhotel, manager)    24\n",
       "57163               (hampton, inn, suites)    23\n",
       "24435                 (good, night, sleep)    21\n",
       "26653                    (new, york, city)    20\n",
       "50576                  (first, time, stay)    19\n",
       "36210                (front, desk, people)    19\n",
       "818         (excellent, customer, service)    17\n",
       "58894                (front, desk, person)    17\n",
       "2639             (air, conditioning, unit)    16\n",
       "6981            (great, customer, service)    16\n",
       "41181                    (hard, boil, egg)    15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "trigramas_filtrados.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já temos os bigramas e trigramas mais relevantes por frequência. Vamos usar os outros métodos e depois comparar todos eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estratégia 2 - Buscando Bigramas e Trigramas Mais Relevantes nos Comentários Por PMI\n",
    "\n",
    "PMI significa Pointwise Mutual Information\n",
    "\n",
    "PMI é um score que mede a probabilidade com que as palavras co-ocorrem mais do que se fossem independentes. No entanto, é muito sensível à combinação rara de palavras. Por exemplo, se um bigrama aleatório 'abc xyz' aparecer e nem 'abc' nem 'xyz' aparecerem em nenhum outro lugar do texto, 'abc xyz' será identificado como bigrama altamente significativo quando poderia ser apenas um erro ortográfico aleatório ou um frase muito rara para generalizar como um bigrama. Portanto, esse método é frequentemente usado com um filtro de frequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos retornar somente bigramas com 20 ou mais ocorrências\n",
    "buscaBigramas.apply_freq_filter(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos a tabela\n",
    "PMITabBigramas = pd.DataFrame(list(buscaBigramas.score_ngrams(bigramas.pmi)), \n",
    "                              columns = ['Bigrama', 'PMI']).sort_values(by = 'PMI', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigrama</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(sarah, junge)</td>\n",
       "      <td>14.480538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(santa, monica)</td>\n",
       "      <td>14.431628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(octavia, margineanhotel)</td>\n",
       "      <td>14.384322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(dixie, krauss)</td>\n",
       "      <td>14.294125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(honua, kai)</td>\n",
       "      <td>14.294125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bigrama        PMI\n",
       "0             (sarah, junge)  14.480538\n",
       "1            (santa, monica)  14.431628\n",
       "2  (octavia, margineanhotel)  14.384322\n",
       "3            (dixie, krauss)  14.294125\n",
       "4               (honua, kai)  14.294125"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "PMITabBigramas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos retornar somente trigramas com 20 ou mais ocorrências\n",
    "buscaTrigramas.apply_freq_filter(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos a tabela\n",
    "PMITabTrigramas = pd.DataFrame(list(buscaTrigramas.score_ngrams(trigramas.pmi)), \n",
    "                               columns = ['Trigrama', 'PMI']).sort_values(by = 'PMI', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigrama</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(octavia, margineanhotel, manager)</td>\n",
       "      <td>25.164421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(maingate, near, angel)</td>\n",
       "      <td>24.668123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(suites, anaheim, maingate)</td>\n",
       "      <td>24.647750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(towneplace, suites, anaheim)</td>\n",
       "      <td>24.477825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(near, angel, stadium)</td>\n",
       "      <td>23.732663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Trigrama        PMI\n",
       "0  (octavia, margineanhotel, manager)  25.164421\n",
       "1             (maingate, near, angel)  24.668123\n",
       "2         (suites, anaheim, maingate)  24.647750\n",
       "3       (towneplace, suites, anaheim)  24.477825\n",
       "4              (near, angel, stadium)  23.732663"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "PMITabTrigramas.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estratégia 3 - Buscando Bigramas e Trigramas Mais Relevantes nos Comentários Por Teste t\n",
    "\n",
    "O Teste t é um teste estatístico que assume uma distribuição normal dos dados. Na prática, é um teste de hipóteses, uma das bases da Inferência Estatistica.\n",
    "\n",
    "- H0 é a hipótese nula, que palavras ocorrem em conjunto (bigramas ou trigramas) com determinada probabilidade.\n",
    "- H1 é a hipótese alternativa, que palavras não ocorrem em conjunto (bigramas ou trigramas) com determinada probabilidade.\n",
    "\n",
    "Ao aplicar o Teste t rejeitamos ou não a H0 através do cálculo de um score e assim representamos os Collocations mais relevantes no texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos a tabela para os bigramas\n",
    "# Observe como o resultado do teste t é obtido: buscaBigramas.score_ngrams(bigramas.student_t)\n",
    "TestetTabBigramas = pd.DataFrame(list(buscaBigramas.score_ngrams(bigramas.student_t)), \n",
    "                             columns = ['Bigrama', 'Teste-t']).sort_values(by = 'Teste-t', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos aplicar o filtro pelo tipo de token conforme aplicamos no método 1\n",
    "bigramas_t_filtrados = TestetTabBigramas[TestetTabBigramas.Bigrama.map(lambda x: filtra_tipo_token_bigrama(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigrama</th>\n",
       "      <th>Teste-t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>(front, desk)</td>\n",
       "      <td>30.635746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>(friendly, staff)</td>\n",
       "      <td>17.849233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>(great, location)</td>\n",
       "      <td>17.698775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>(walk, distance)</td>\n",
       "      <td>16.516868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>(free, breakfast)</td>\n",
       "      <td>13.799874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Bigrama    Teste-t\n",
       "25       (front, desk)  30.635746\n",
       "96   (friendly, staff)  17.849233\n",
       "100  (great, location)  17.698775\n",
       "119   (walk, distance)  16.516868\n",
       "174  (free, breakfast)  13.799874"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "bigramas_t_filtrados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos a tabela para os trigramas\n",
    "TestetTabTrigramas = pd.DataFrame(list(buscaTrigramas.score_ngrams(trigramas.student_t)), \n",
    "                                  columns = ['Trigrama', 'Teste-t']).sort_values(by = 'Teste-t', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos aplicar o filtro pelo tipo de token conforme aplicamos no método 1\n",
    "trigramas_t_filtrados = TestetTabTrigramas[TestetTabTrigramas.Trigrama.map(lambda x: filtra_tipo_token_trigrama(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigrama</th>\n",
       "      <th>Teste-t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>(front, desk, staff)</td>\n",
       "      <td>12.726861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>(non, smoking, room)</td>\n",
       "      <td>6.324501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>946</td>\n",
       "      <td>(front, desk, clerk)</td>\n",
       "      <td>6.164333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>973</td>\n",
       "      <td>(regis, new, york)</td>\n",
       "      <td>6.082761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1231</td>\n",
       "      <td>(holiday, inn, express)</td>\n",
       "      <td>5.656853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Trigrama    Teste-t\n",
       "133      (front, desk, staff)  12.726861\n",
       "878      (non, smoking, room)   6.324501\n",
       "946      (front, desk, clerk)   6.164333\n",
       "973        (regis, new, york)   6.082761\n",
       "1231  (holiday, inn, express)   5.656853"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "trigramas_t_filtrados.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estratégia 4 - Buscando Bigramas e Trigramas Mais Relevantes nos Comentários Por Teste do Qui-quadrado\n",
    "\n",
    "O teste do qui-quadrado é uma alternativa ao teste t. O teste do qui-quadrado assume na hipótese nula que as palavras são independentes, assim como no teste t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara a tabela\n",
    "# Observe como estamos coletando a estatística qui-quadrado: buscaBigramas.score_ngrams(bigramas.chi_sq)\n",
    "QuiTabBigramas = pd.DataFrame(list(buscaBigramas.score_ngrams(bigramas.chi_sq)), \n",
    "                              columns = ['Bigrama', 'Qui']).sort_values(by = 'Qui', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigrama</th>\n",
       "      <th>Qui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(honua, kai)</td>\n",
       "      <td>622759.939306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(dixie, krauss)</td>\n",
       "      <td>602669.999877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(wi, fi)</td>\n",
       "      <td>581568.679255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(octavia, margineanhotel)</td>\n",
       "      <td>513238.451417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(sarah, junge)</td>\n",
       "      <td>480054.206713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bigrama            Qui\n",
       "0               (honua, kai)  622759.939306\n",
       "1            (dixie, krauss)  602669.999877\n",
       "2                   (wi, fi)  581568.679255\n",
       "3  (octavia, margineanhotel)  513238.451417\n",
       "4             (sarah, junge)  480054.206713"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "QuiTabBigramas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara a tabela\n",
    "QuiTabTrigramas = pd.DataFrame(list(buscaTrigramas.score_ngrams(trigramas.chi_sq)), \n",
    "                               columns = ['Trigrama', 'Qui']).sort_values(by = 'Qui', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigrama</th>\n",
       "      <th>Qui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(octavia, margineanhotel, manager)</td>\n",
       "      <td>9.025196e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(suites, anaheim, maingate)</td>\n",
       "      <td>7.885578e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(towneplace, suites, anaheim)</td>\n",
       "      <td>7.476702e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(maingate, near, angel)</td>\n",
       "      <td>7.197947e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(near, angel, stadium)</td>\n",
       "      <td>3.345487e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Trigrama           Qui\n",
       "0  (octavia, margineanhotel, manager)  9.025196e+08\n",
       "1         (suites, anaheim, maingate)  7.885578e+08\n",
       "2       (towneplace, suites, anaheim)  7.476702e+08\n",
       "3             (maingate, near, angel)  7.197947e+08\n",
       "4              (near, angel, stadium)  3.345487e+08"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "QuiTabTrigramas.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação e Resultado Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos extrair os 10 Collocations bigramas mais relevantes de acordo com cada um dos 4 métodos usados\n",
    "# Lembre-se que aplicamos filtros para remover as stopwords e devemos usar a tabela filtrada\n",
    "metodo1_bigrama = bigramas_filtrados[:10].Bigrama.values\n",
    "metodo2_bigrama = PMITabBigramas[:10].Bigrama.values\n",
    "metodo3_bigrama = bigramas_t_filtrados[:10].Bigrama.values\n",
    "metodo4_bigrama = QuiTabBigramas[:10].Bigrama.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos extrair os 10 Collocations trigramas mais relevantes de acordo com cada um dos 4 métodos usados\n",
    "# Lembre-se que aplicamos filtros para remover as stopwords e devemos usar a tabela filtrada\n",
    "metodo1_trigrama = trigramas_filtrados[:10].Trigrama.values\n",
    "metodo2_trigrama = PMITabTrigramas[:10].Trigrama.values\n",
    "metodo3_trigrama = trigramas_t_filtrados[:10].Trigrama.values\n",
    "metodo4_trigrama = QuiTabTrigramas[:10].Trigrama.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar um super dataframe com todos os resultados para bigramas\n",
    "comparaBigramas = pd.DataFrame([metodo1_bigrama, metodo2_bigrama, metodo3_bigrama, metodo4_bigrama]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nossa tabela precisa de nomes para as colunas\n",
    "comparaBigramas.columns = ['Frequência', \n",
    "                           'PMI', \n",
    "                           'Teste-t', \n",
    "                           'Teste Qui-quadrado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_578af440_30c6_11eb_969c_3998d049f586row0_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row0_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row0_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row0_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row1_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row1_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row1_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row1_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row2_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row2_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row2_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row2_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row3_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row3_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row3_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row3_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row4_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row4_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row4_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row4_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row5_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row5_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row5_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row5_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row6_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row6_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row6_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row6_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row7_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row7_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row7_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row7_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row8_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row8_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row8_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row8_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row9_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row9_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row9_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }    #T_578af440_30c6_11eb_969c_3998d049f586row9_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  pink;\n",
       "            border-color:  pink;\n",
       "        }</style><table id=\"T_578af440_30c6_11eb_969c_3998d049f586\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Frequência</th>        <th class=\"col_heading level0 col1\" >PMI</th>        <th class=\"col_heading level0 col2\" >Teste-t</th>        <th class=\"col_heading level0 col3\" >Teste Qui-quadrado</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row0_col0\" class=\"data row0 col0\" >('front', 'desk')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row0_col1\" class=\"data row0 col1\" >('sarah', 'junge')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row0_col2\" class=\"data row0 col2\" >('front', 'desk')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row0_col3\" class=\"data row0 col3\" >('honua', 'kai')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row1_col0\" class=\"data row1 col0\" >('friendly', 'staff')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row1_col1\" class=\"data row1 col1\" >('santa', 'monica')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row1_col2\" class=\"data row1 col2\" >('friendly', 'staff')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row1_col3\" class=\"data row1 col3\" >('dixie', 'krauss')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row2_col0\" class=\"data row2 col0\" >('great', 'location')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row2_col1\" class=\"data row2 col1\" >('octavia', 'margineanhotel')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row2_col2\" class=\"data row2 col2\" >('great', 'location')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row2_col3\" class=\"data row2 col3\" >('wi', 'fi')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row3_col0\" class=\"data row3 col0\" >('walk', 'distance')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row3_col1\" class=\"data row3 col1\" >('dixie', 'krauss')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row3_col2\" class=\"data row3 col2\" >('walk', 'distance')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row3_col3\" class=\"data row3 col3\" >('octavia', 'margineanhotel')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row4_col0\" class=\"data row4 col0\" >('clean', 'room')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row4_col1\" class=\"data row4 col1\" >('honua', 'kai')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row4_col2\" class=\"data row4 col2\" >('free', 'breakfast')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row4_col3\" class=\"data row4 col3\" >('sarah', 'junge')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row5_col0\" class=\"data row5 col0\" >('free', 'breakfast')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row5_col1\" class=\"data row5 col1\" >('san', 'francisco')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row5_col2\" class=\"data row5 col2\" >('customer', 'service')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row5_col3\" class=\"data row5 col3\" >('santa', 'monica')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row6_col0\" class=\"data row6 col0\" >('customer', 'service')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row6_col1\" class=\"data row6 col1\" >('wi', 'fi')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row6_col2\" class=\"data row6 col2\" >('continental', 'breakfast')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row6_col3\" class=\"data row6 col3\" >('front', 'desk')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row7_col0\" class=\"data row7 col0\" >('hotel', 'staff')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row7_col1\" class=\"data row7 col1\" >('angel', 'stadium')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row7_col2\" class=\"data row7 col2\" >('desk', 'staff')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row7_col3\" class=\"data row7 col3\" >('   ', 'more')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row8_col0\" class=\"data row8 col0\" >('desk', 'staff')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row8_col1\" class=\"data row8 col1\" >('anaheim', 'maingate')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row8_col2\" class=\"data row8 col2\" >('good', 'western')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row8_col3\" class=\"data row8 col3\" >('french', 'quarter')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_578af440_30c6_11eb_969c_3998d049f586level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row9_col0\" class=\"data row9 col0\" >('continental', 'breakfast')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row9_col1\" class=\"data row9 col1\" >('fire', 'pit')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row9_col2\" class=\"data row9 col2\" >('comfortable', 'bed')</td>\n",
       "                        <td id=\"T_578af440_30c6_11eb_969c_3998d049f586row9_col3\" class=\"data row9 col3\" >('las', 'vegas')</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f585aeeafd0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela - Padrão CSS\n",
    "comparaBigramas.style.set_properties(**{'background-color': 'blue', \n",
    "                                        'color': 'pink', \n",
    "                                        'border-color': 'pink'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar um super dataframe com todos os resultados para trigramas\n",
    "comparaTrigramas = pd.DataFrame([metodo1_trigrama, metodo2_trigrama, metodo3_trigrama, metodo4_trigrama]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nossa tabela precisa de nomes para as colunas\n",
    "comparaTrigramas.columns = ['Frequência', \n",
    "                            'PMI', \n",
    "                            'Teste-t', \n",
    "                            'Teste Qui-quadrado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_63382dee_30c6_11eb_969c_3998d049f586row0_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row0_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row0_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row0_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row1_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row1_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row1_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row1_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row2_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row2_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row2_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row2_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row3_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row3_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row3_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row3_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row4_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row4_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row4_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row4_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row5_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row5_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row5_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row5_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row6_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row6_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row6_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row6_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row7_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row7_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row7_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row7_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row8_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row8_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row8_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row8_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row9_col0 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row9_col1 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row9_col2 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }    #T_63382dee_30c6_11eb_969c_3998d049f586row9_col3 {\n",
       "            background-color:  blue;\n",
       "            color:  white;\n",
       "            border-color:  white;\n",
       "        }</style><table id=\"T_63382dee_30c6_11eb_969c_3998d049f586\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Frequência</th>        <th class=\"col_heading level0 col1\" >PMI</th>        <th class=\"col_heading level0 col2\" >Teste-t</th>        <th class=\"col_heading level0 col3\" >Teste Qui-quadrado</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row0_col0\" class=\"data row0 col0\" >('front', 'desk', 'staff')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row0_col1\" class=\"data row0 col1\" >('octavia', 'margineanhotel', 'manager')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row0_col2\" class=\"data row0 col2\" >('front', 'desk', 'staff')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row0_col3\" class=\"data row0 col3\" >('octavia', 'margineanhotel', 'manager')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row1_col0\" class=\"data row1 col0\" >('non', 'smoking', 'room')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row1_col1\" class=\"data row1 col1\" >('maingate', 'near', 'angel')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row1_col2\" class=\"data row1 col2\" >('non', 'smoking', 'room')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row1_col3\" class=\"data row1 col3\" >('suites', 'anaheim', 'maingate')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row2_col0\" class=\"data row2 col0\" >('front', 'desk', 'clerk')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row2_col1\" class=\"data row2 col1\" >('suites', 'anaheim', 'maingate')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row2_col2\" class=\"data row2 col2\" >('front', 'desk', 'clerk')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row2_col3\" class=\"data row2 col3\" >('towneplace', 'suites', 'anaheim')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row3_col0\" class=\"data row3 col0\" >('regis', 'new', 'york')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row3_col1\" class=\"data row3 col1\" >('towneplace', 'suites', 'anaheim')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row3_col2\" class=\"data row3 col2\" >('regis', 'new', 'york')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row3_col3\" class=\"data row3 col3\" >('maingate', 'near', 'angel')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row4_col0\" class=\"data row4 col0\" >('holiday', 'inn', 'express')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row4_col1\" class=\"data row4 col1\" >('near', 'angel', 'stadium')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row4_col2\" class=\"data row4 col2\" >('holiday', 'inn', 'express')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row4_col3\" class=\"data row4 col3\" >('near', 'angel', 'stadium')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row5_col0\" class=\"data row5 col0\" >('suites', 'anaheim', 'maingate')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row5_col1\" class=\"data row5 col1\" >('anaheim', 'maingate', 'near')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row5_col2\" class=\"data row5 col2\" >('suites', 'anaheim', 'maingate')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row5_col3\" class=\"data row5 col3\" >('anaheim', 'maingate', 'near')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row6_col0\" class=\"data row6 col0\" >('flat', 'screen', 'tv')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row6_col1\" class=\"data row6 col1\" >('flat', 'screen', 'tv')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row6_col2\" class=\"data row6 col2\" >('flat', 'screen', 'tv')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row6_col3\" class=\"data row6 col3\" >('flat', 'screen', 'tv')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row7_col0\" class=\"data row7 col0\" >('hilton', 'garden', 'inn')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row7_col1\" class=\"data row7 col1\" >('holiday', 'inn', 'express')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row7_col2\" class=\"data row7 col2\" >('hilton', 'garden', 'inn')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row7_col3\" class=\"data row7 col3\" >('holiday', 'inn', 'express')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row8_col0\" class=\"data row8 col0\" >('maingate', 'near', 'angel')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row8_col1\" class=\"data row8 col1\" >('regis', 'new', 'york')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row8_col2\" class=\"data row8 col2\" >('maingate', 'near', 'angel')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row8_col3\" class=\"data row8 col3\" >('regis', 'new', 'york')</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_63382dee_30c6_11eb_969c_3998d049f586level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row9_col0\" class=\"data row9 col0\" >('octavia', 'margineanhotel', 'manager')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row9_col1\" class=\"data row9 col1\" >('hilton', 'garden', 'inn')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row9_col2\" class=\"data row9 col2\" >('octavia', 'margineanhotel', 'manager')</td>\n",
       "                        <td id=\"T_63382dee_30c6_11eb_969c_3998d049f586row9_col3\" class=\"data row9 col3\" >('hilton', 'garden', 'inn')</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f585b5b1350>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza a tabela\n",
    "comparaTrigramas.style.set_properties(**{'background-color': 'blue', \n",
    "                                         'color': 'white', \n",
    "                                         'border-color': 'white'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Podemos ver que os métodos PMI e Qui-quadrado fornecem bons resultados. Seus resultados também são semelhantes. \n",
    "\n",
    "Mas os métodos de Frequência e Teste-t apresentam os melhores resutados e são também muito semelhantes entre si. \n",
    "\n",
    "Em aplicativos reais, podemos observar a lista e definir um limite em um valor a partir de quando a lista para de fazer sentido. Também podemos fazer testes diferentes para ver qual lista parece fazer mais sentido para um determinado conjunto de dados. \n",
    "\n",
    "Como alternativa, podemos combinar resultados de várias listas. Uma boa escolha é multiplicar o PMI e a Frequência para levar em consideração o aumento da probabilidade e a frequência da ocorrência. Ou multiplicar a frequência pelo Teste-t criando assim um índice único de relevância das Collocations.\n",
    "\n",
    "Para este trabalho, vamos considerar as Collocations calculadas por Frequência como as mais relevantes. A escolha se deve ao fato de que as suposições para o Teste-t não foram validadas e usar seu resultado seria inadequado. Salvamos a coluna de frequência do dataframe final em formato csv ou txt e encaminhamos à área de Marketing da rede de hotéis.\n",
    "\n",
    "Você pode continuar o trabalho e alterar os métodos acima, se desejar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
